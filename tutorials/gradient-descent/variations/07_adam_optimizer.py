# -*- coding: utf-8 -*-
"""07_adam_optimizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12pq3UZddliElC37F97mvDr1dvjWCs7iL
"""

import numpy as np

def adam(X, y, lr = 0.01, n_iters = 1000, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):
  n_samples, n_features = X.shape
  w = np.zeros(n_features)
  m = np.zeros(n_features)
  v = np.zeros(n_features)
  history = []

  for t in range(1, n_iters + 1):
    pred = X.dot(w)
    error = pred - y
    grad = (2 / n_samples) * (X.T.dot(error))

    m = beta1 * m + (1 - beta1) * grad
    v = beta2 * v + (1 - beta2) * grad**2

    m_hat = m / (1 - beta1**t)
    v_hat = m / (1 - beta2**t)

    w -= lr * m_hat / (np.sqrt(v_hat) + epsilon)
    history.append(np.mean(error**2))

  return w, history