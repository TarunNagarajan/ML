# -*- coding: utf-8 -*-
"""02_stochastic_gradient.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QNn2KjD_nSaGrOpJAkriguZWZJoqpCpj
"""

import numpy as np

def stochastic_gradient_descent(X, y, lr = 0.01, n_epochs = 50, batch_size = 1):
  n_samples, n_features = X.shape
  w = np.zeros(n_features)
  history = []

  for _ in range(n_epochs):
    perm = np.random.permutation(n_samples)
    X_shuffled = X[perm]
    y_shuffled = y[perm]

    for i in range(0, n_samples, batch_size):
      X_batch = X_shuffled[i:i+batch_size]
      y_batch = y_shuffled[i:i+batch_size]

      pred = X_batch.dot(w)
      error = pred - y_batch
      grad = (2 / batch_size) * (X_batch.T.dot(error))

      w -= grad * lr

    preds = X.dot(w)
    loss = np.mean((preds - y)**2)
    history.append(loss)
  return w, history