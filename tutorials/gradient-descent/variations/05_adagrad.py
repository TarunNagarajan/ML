# -*- coding: utf-8 -*-
"""05_adagrad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z1rptCYmo33lvbT9P_a8du4zYhusb6fq
"""

import numpy as np

def adagrad(X, y, lr = 0.1, n_epochs = 100, epsilon = 1e-8):

  n_samples, n_features = X.shape
  w = np.zeros(n_features)
  G = np.zeros(n_features)
  history = []

  for epoch in range(n_epochs):
    grad_sum = np.zeros_like(w)
    for i in range(n_samples):
      xi = X[i]
      yi = y[i]
      pred = xi.dot(w)
      error = pred - yi

      grad = 2 * xi * error
      G += grad**2
      adjusted_lr = lr / (np.sqrt(G) + epsilon)
      w -= adjusted_lr * grad

    preds = X.dot(w)
    loss = np.mean((preds - y)**2)
    history.append(loss)

  return w, history