# Machine Learning 
| Day                                                              | Task                                                                                                                                                                   |
| ---------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Phase 1: Foundations & Classical ML (Days 1–30)**              |                                                                                                                                                                        |
| 1                                                                | Linear algebra: implement vector operations & matrix multiplication in Python                                                                                          |
| 2                                                                | Implement LU & QR factorizations from scratch; benchmark                                                                                                               |
| 3                                                                | Code eigen decomposition & SVD; apply to image compression                                                                                                             |
| 4                                                                | PCA derivation & implementation; run on MNIST                                                                                                                          |
| 5                                                                | Probability: implement Bernoulli, Binomial, Gaussian samplers                                                                                                          |
| 6                                                                | Simulate distributions; verify expectation & variance empirically                                                                                                      |
| 7                                                                | **Rest Day**                                                                                                                                                           |
| 8                                                                | Bayesian inference: code Beta–Binomial conjugate prior                                                                                                                 |
| 9                                                                | Hypothesis testing: t-test & chi-square from scratch                                                                                                                   |
| 10                                                               | Logistic regression derivation; code with gradient descent                                                                                                             |
| 11                                                               | L2-regularized logistic regression; tune on real dataset                                                                                                               |
| 12                                                               | SVM primal/dual derivation; implement quadratic solver                                                                                                                 |
| 13                                                               | SVM hard/soft-margin; visualize decision boundary                                                                                                                      |
| 14                                                               | **Rest Day**                                                                                                                                                           |
| 15                                                               | Decision trees: implement ID3/CART; test on UCI dataset                                                                                                                |
| 16                                                               | Random forests: build ensemble; measure OOB error                                                                                                                      |
| 17                                                               | AdaBoost: implement boosting loop; compare accuracy                                                                                                                    |
| 18                                                               | Gradient boosting & XGBoost pipeline; tune on Kaggle data                                                                                                              |
| 19                                                               | K-means: implement Lloyd’s algorithm; compare to sklearn                                                                                                               |
| 20                                                               | Hierarchical clustering & DBSCAN: code & apply                                                                                                                         |
| 21                                                               | **Rest Day**                                                                                                                                                           |
| 22                                                               | t-SNE: implement basic version; visualize on MNIST                                                                                                                     |
| 23                                                               | UMAP: integrate library; compare embeddings vs t-SNE                                                                                                                   |
| 24                                                               | Autoencoder: code in PyTorch; compare to PCA                                                                                                                           |
| 25                                                               | Time-series: implement AR, MA, ARIMA models                                                                                                                            |
| 26                                                               | Recommender: matrix-factorization collaborative filtering                                                                                                              |
| 27                                                               | **Rest Day**                                                                                                                                                           |
| 28                                                               | Evaluation metrics: code precision/recall/F1 & ROC-AUC                                                                                                                 |
| 29                                                               | Cross-validation & hyperparameter search frameworks                                                                                                                    |
| 30                                                               | Scikit-learn pipeline: preprocess → model → CV                                                                                                                         |
| **Phase 2: Deep Learning Foundations (Days 31–60)**              |                                                                                                                                                                        |
| 31                                                               | Neural net forward & backward pass in numpy                                                                                                                            |
| 32                                                               | Train MLP on MNIST; compare numpy vs PyTorch                                                                                                                           |
| 33                                                               | PyTorch basics: DataLoader & training loop                                                                                                                             |
| 34                                                               | TensorFlow basics: build equivalent MNIST MLP                                                                                                                          |
| 35                                                               | Convolution: code 2D conv & pooling in numpy                                                                                                                           |
| 36                                                               | CNN in PyTorch; train on CIFAR-10 baseline                                                                                                                             |
| 37                                                               | Data augmentation pipeline: flips, crops, color jitter                                                                                                                 |
| 38                                                               | BatchNorm & learning-rate schedules; integrate                                                                                                                         |
| 39                                                               | ResNet block: implement & train small ResNet                                                                                                                           |
| 40                                                               | **Rest Day**                                                                                                                                                           |
| 41                                                               | RNN cell & sequence training in PyTorch                                                                                                                                |
| 42                                                               | LSTM & GRU implementation; benchmark on text task                                                                                                                      |
| 43                                                               | Transformer: derive & code single attention block                                                                                                                      |
| 44                                                               | Build mini-transformer; train on toy translation data                                                                                                                  |
| 45                                                               | Fine-tune BERT on classification (e.g., SST-2)                                                                                                                         |
| 46                                                               | GAN: build DCGAN for MNIST generation                                                                                                                                  |
| 47                                                               | VAE: train on Fashion-MNIST; visualize latent space                                                                                                                    |
| 48                                                               | Seq2seq: attention-based encoder–decoder implementation                                                                                                                |
| 49                                                               | Beam search decoding; integrate into seq2seq model                                                                                                                     |
| 50                                                               | **Rest Day**                                                                                                                                                           |
| 51                                                               | Serve DL model via Flask; profile inference bottlenecks                                                                                                                |
| 52                                                               | Model compression: survey quantization & pruning theory                                                                                                                |
| 53                                                               | Post-training static quantization in PyTorch                                                                                                                           |
| 54                                                               | Dynamic quantization & pruning comparison                                                                                                                              |
| 55                                                               | Quantization-aware training (QAT) implementation                                                                                                                       |
| 56                                                               | Structured (channel) pruning; code & benchmark                                                                                                                         |
| 57                                                               | Knowledge distillation: teacher→student training                                                                                                                       |
| 58                                                               | **Capstone 1 (Day 60):** Build an end-to-end optimized CNN inference pipeline (quantized, pruned, distilled) with benchmarks                                           |
| 59                                                               | Neural Architecture Search (NAS) basics: implement simple search                                                                                                       |
| 60                                                               | **Rest Day**                                                                                                                                                           |
| **Phase 3: Inference & Hardware-Aware ML (Days 61–90)**          |                                                                                                                                                                        |
| 61                                                               | NVIDIA GPU architecture deep dive; CUDA profiling                                                                                                                      |
| 62                                                               | Profile PyTorch CUDA kernels; optimize batch sizes                                                                                                                     |
| 63                                                               | Install & run TensorRT demo; record speedup                                                                                                                            |
| 64                                                               | Convert PyTorch→ONNX→TensorRT; benchmark inference                                                                                                                     |
| 65                                                               | **Rest Day**                                                                                                                                                           |
| 66                                                               | ARM CPU microarchitecture study; pipeline analysis                                                                                                                     |
| 67                                                               | Convert model to TFLite; run on Raspberry Pi benchmark                                                                                                                 |
| 68                                                               | ONNX Runtime vs TFLite on ARM; compare metrics                                                                                                                         |
| 69                                                               | Mixed-precision (FP16) inference & training in PyTorch                                                                                                                 |
| 70                                                               | Automatic Mixed Precision (AMP) + layer freezing                                                                                                                       |
| 71                                                               | Sparse tensor ops in PyTorch; implement example                                                                                                                        |
| 72                                                               | **Rest Day**                                                                                                                                                           |
| 73                                                               | Graph optimization: fuse ops with ONNX tools                                                                                                                           |
| 74                                                               | Build custom TensorRT plugin for custom op                                                                                                                             |
| 75                                                               | GNN: implement GCN layer; train on Cora dataset                                                                                                                        |
| 76                                                               | GraphSAGE & GAT implementations; compare results                                                                                                                       |
| 77                                                               | Quantize & prune GNN models; benchmark inference                                                                                                                       |
| 78                                                               | Profiling end-to-end: NVProf/Nsight on GNN inference                                                                                                                   |
| 79                                                               | **Rest Day**                                                                                                                                                           |
| 80                                                               | Distributed training with PyTorch DDP setup                                                                                                                            |
| 81                                                               | Model & pipeline parallelism: implement micro-batch pipelining                                                                                                         |
| 82                                                               | L-BFGS optimizer from scratch; test on small task                                                                                                                      |
| 83                                                               | Automate benchmarking: scripts & logging dashboards                                                                                                                    |
| 84                                                               | Reproduce 1 inference-optimization paper experiment; document                                                                                                          |
| 85                                                               | **Capstone 2 Prep (Day 90):** Draft novel inference-optimization prototype                                                                                             |
| 86                                                               | **Rest Day**                                                                                                                                                           |
| **Phase 4: Novel Contributions & Advanced Topics (Days 91–120)** |                                                                                                                                                                        |
| 87                                                               | Implement prototype of novel inference-optimization method                                                                                                             |
| 88                                                               | Benchmark prototype vs SOTA; collect metrics                                                                                                                           |
| 89                                                               | Neural Architecture Search: implement NAS on small CNN                                                                                                                 |
| 90                                                               | Self-supervised learning: train SimCLR on CIFAR-10                                                                                                                     |
| 91                                                               | **Rest Day**                                                                                                                                                           |
| 92                                                               | Meta-learning: implement MAML on toy tasks                                                                                                                             |
| 93                                                               | Automated Mixed-Precision search: code runtime tuner                                                                                                                   |
| 94                                                               | Differentiable programming: implement custom grad op                                                                                                                   |
| 95                                                               | Advanced quantization: PTQ vs QAT comparison study                                                                                                                     |
| 96                                                               | **Rest Day**                                                                                                                                                           |
| 97                                                               | Hardware-aware NAS: include latency in search objective                                                                                                                |
| 98                                                               | Graph optimization deep dive: build custom pass with ONNX                                                                                                              |
| 99                                                               | Sparse GNN inference: optimize message-passing kernels                                                                                                                 |
| 100                                                              | **Rest Day**                                                                                                                                                           |
| 101                                                              | Low-level kernel optimization: write CUDA kernel & benchmark                                                                                                           |
| 102                                                              | FPGA inference basics: explore HLS tools (Vivado HLS)                                                                                                                  |
| 103                                                              | Implement simple FPGA design for matrix multiply                                                                                                                       |
| 104                                                              | **Rest Day**                                                                                                                                                           |
| 105                                                              | Advanced compiler optimizations: use TVM to tune model                                                                                                                 |
| 106                                                              | Integrate TVM-tuned model into inference pipeline                                                                                                                      |
| 107                                                              | End-to-end benchmarking suite: add NAS & TVM results                                                                                                                   |
| 108                                                              | **Capstone 2 (Day 120):** Publish code & benchmarks for novel inference-optimization, NAS, and HW-aware improvements                                                   |
| 109                                                              | **Rest Day**                                                                                                                                                           |
| **Phase 5: Interview Prep & Final Capstone (Days 121–150)**      |                                                                                                                                                                        |
| 110                                                              | ML system design: implement a scalable inference service                                                                                                               |
| 111                                                              | Profiling & scaling: benchmark service under load                                                                                                                      |
| 112                                                              | Automated scaling script: Kubernetes & container metrics                                                                                                               |
| 113                                                              | **Rest Day**                                                                                                                                                           |
| 114                                                              | End-to-end FastAPI + CUDA inference backend implementation                                                                                                             |
| 115                                                              | React/Streamlit frontend: visualize model performance                                                                                                                  |
| 116                                                              | Integrate live benchmarks in UI; automate data refresh                                                                                                                 |
| 117                                                              | **Rest Day**                                                                                                                                                           |
| 118                                                              | TensorRT plugin extension: add custom op and test                                                                                                                      |
| 119                                                              | TVM end-to-end: compile & deploy model to edge device                                                                                                                  |
| 120                                                              | **Rest Day**                                                                                                                                                           |
| 121                                                              | Remote inference optimization: multi-node RPC benchmarking                                                                                                             |
| 122                                                              | Profiling & optimizing RPC communication overhead                                                                                                                      |
| 123                                                              | **Rest Day**                                                                                                                                                           |
| 124                                                              | End-to-end demo containerization: Docker & compose                                                                                                                     |
| 125                                                              | Cloud deployment: AWS/GCP edge instance benchmarking                                                                                                                   |
| 126                                                              | **Rest Day**                                                                                                                                                           |
| 127                                                              | Integrate FPGA-accelerated inference into demo                                                                                                                         |
| 128                                                              | Latency & throughput analysis across backends                                                                                                                          |
| 129                                                              | **Rest Day**                                                                                                                                                           |
| 130                                                              | Complete full-stack demo; stress-test under varied loads                                                                                                               |
| 131                                                              | **Rest Day**                                                                                                                                                           |
| 132                                                              | Polish code & docs: ensure reproducibility of all experiments                                                                                                          |
| 133                                                              | Final end-to-end automated benchmark suite                                                                                                                             |
| 134                                                              | **Rest Day**                                                                                                                                                           |
| 135                                                              | **Capstone 3 (Day 150):** Deliver full interactive demo (FastAPI + frontend + multi-backend inference) with comprehensive benchmarks and codebase ready for recruiters |
| 136–150                                                          | Buffer days: catch up, extra practice on weak areas, rest if needed                                                                                                    |

